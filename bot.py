import os
import random
import smtplib
import asyncio
import requests
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from email.mime.base import MIMEBase
from email import encoders
from bs4 import BeautifulSoup

# --- Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª (ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø³ÙŠÙƒØ±Øª Ø¨Ø§Ø³Ù… API_KEY ÙÙŠ Ù‚ÙŠØª Ù‡Ø¨) ---
SENDER_EMAIL = "oedn305@gmail.com"
EMAIL_PASSWORD = os.getenv("API_KEY") 
DB_FILE = "applied_emails.txt"

def get_cv_file():
    """Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ù„Ù Ø§Ù„Ø³ÙŠØ±Ø© Ø§Ù„Ø°Ø§ØªÙŠØ© PDF ÙÙŠ Ø§Ù„Ù…Ø¬Ù„Ø¯"""
    return next((f for f in os.listdir('.') if f.lower().endswith('.pdf')), None)

def send_application_email(target_email):
    """Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø¥ÙŠÙ…ÙŠÙ„ Ù…Ø¹ Ø§Ù„Ù…Ø±ÙÙ‚"""
    try:
        msg = MIMEMultipart()
        msg['From'] = SENDER_EMAIL
        msg['To'] = target_email
        msg['Subject'] = f"Job Application - High School Graduate - Ref:{random.randint(1000, 9999)}"
        
        body = """Greetings,

I am writing to express my interest in potential job opportunities at your esteemed organization. 
I am a High School Graduate, highly motivated, and ready to contribute to your team.

Please find my CV attached for your review.

Best Regards,"""
        
        msg.attach(MIMEText(body, 'plain'))

        cv_path = get_cv_file()
        if cv_path:
            with open(cv_path, "rb") as f:
                part = MIMEBase('application', 'octet-stream')
                part.set_payload(f.read())
                encoders.encode_base64(part)
                part.add_header('Content-Disposition', f'attachment; filename="CV_Saudi_Candidate.pdf"')
                msg.attach(part)

        with smtplib.SMTP('smtp.gmail.com', 587) as server:
            server.starttls()
            server.login(SENDER_EMAIL, EMAIL_PASSWORD)
            server.send_message(msg)
        return True
    except Exception as e:
        print(f"âŒ ØªØ¹Ø°Ø± Ø§Ù„Ø¥Ø±Ø³Ø§Ù„ Ø¥Ù„Ù‰ {target_email}: {str(e)}")
        return False

def get_real_emails():
    """Ù‚Ø§Ø¦Ù…Ø© Ø¥ÙŠÙ…ÙŠÙ„Ø§Øª Ø­Ù‚ÙŠÙ‚ÙŠØ© ÙˆÙ…Ø­Ø¯Ø«Ø© Ù„Ø¬Ù‡Ø§Øª ØªØ·Ù„Ø¨ Ø«Ø§Ù†ÙˆÙŠ"""
    return [
        "recruitment@panda.com.sa",      # Ø¨Ù†Ø¯Ù‡
        "careers@jarir.com",             # Ø¬Ø±ÙŠØ±
        "jobs@almarai.com",              # Ø§Ù„Ù…Ø±Ø§Ø¹ÙŠ
        "recruitment@nwc.com.sa",        # Ø´Ø±ÙƒØ© Ø§Ù„Ù…ÙŠØ§Ù‡
        "hr@saudicatering.com",          # Ø§Ù„ØªÙ…ÙˆÙŠÙ†
        "careers@nesma.com",             # Ù†Ø³Ù…Ø§
        "jobs@kfb.com.sa",               # Ù…Ø®Ø§Ø¨Ø² Ø§Ù„ÙÙŠØµÙ„
        "recruitment@alkhorayef.com",    # Ø§Ù„Ø®Ø±ÙŠÙ
        "jobs@daralarkan.com",           # Ø¯Ø§Ø± Ø§Ù„Ø£Ø±ÙƒØ§Ù†
        "careers@alfanar.com",           # Ø§Ù„ÙÙ†Ø§Ø±
        "jobs@shaker.com.sa",            # Ù…Ø¬Ù…ÙˆØ¹Ø© Ø´Ø§ÙƒØ±
        "hr@sraco.com.sa",               # Ø³Ø±Ø§ÙƒÙˆ (ØµÙŠØ§Ù†Ø© ÙˆØªØ´ØºÙŠÙ„)
        "jobs@zamilindustrial.com",      # Ø§Ù„Ø²Ø§Ù…Ù„
        "recruitment@fawazalhokair.com", # Ø§Ù„Ø­ÙƒÙŠØ± (ØªØ¬Ø²Ø¦Ø©)
        "careers@appareluae.com",        # Ø£Ø¨Ø§Ø±ÙŠÙ„ (Ù…Ù„Ø§Ø¨Ø³ ÙˆÙ…Ø§Ø±ÙƒØ§Øª)
        "jobs@binzagr.com.sa"            # Ø¨Ù† Ø²Ù‚Ø± (ØªÙˆØ²ÙŠØ¹)
    ]

def scrape_direct_links():
    """Ø³Ø­Ø¨ Ø£Ø­Ø¯Ø« Ø±ÙˆØ§Ø¨Ø· Ø§Ù„ØªÙˆØ¸ÙŠÙ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø© Ù„Ø­Ù…Ù„Ø© Ø§Ù„Ø«Ø§Ù†ÙˆÙŠØ©"""
    print("\nğŸ” Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø±ÙˆØ§Ø¨Ø· ØªÙ‚Ø¯ÙŠÙ… Ù…Ø¨Ø§Ø´Ø±Ø© (Ø£Ø­Ø¯Ø« Ø§Ù„ÙˆØ¸Ø§Ø¦Ù)...")
    url = "https://saudi.tanqeeb.com/ar/s/ÙˆØ¸Ø§Ø¦Ù/ÙˆØ¸Ø§Ø¦Ù-Ù„Ø­Ù…Ù„Ø©-Ø§Ù„Ø«Ø§Ù†ÙˆÙŠØ©"
    links = []
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        r = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(r.text, 'html.parser')
        for a in soup.find_all('a', href=True):
            if 'Ø«Ø§Ù†ÙˆÙŠØ©' in a.text:
                full_url = a['href'] if a['href'].startswith('http') else f"https://saudi.tanqeeb.com{a['href']}"
                links.append(f"{a.text.strip()[:50]}... -> {full_url}")
                if len(links) >= 5: break
    except: pass
    return links

async def run_bot():
    cv = get_cv_file()
    if not cv:
        print("âŒ Ø®Ø·Ø£: Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„Ù PDF (Ø§Ù„Ø³ÙŠØ±Ø© Ø§Ù„Ø°Ø§ØªÙŠØ©)!")
        return
    if not EMAIL_PASSWORD:
        print("âŒ Ø®Ø·Ø£: Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ø¨Ø§Ø³ÙˆØ±Ø¯ (API_KEY) ÙÙŠ Ø§Ù„Ø³ÙŠÙƒØ±ØªØ³!")
        return

    print(f"ğŸš€ Ø¨Ø¯Ø¡ Ø§Ù„Ø¹Ù…Ù„... Ø§Ù„Ø³ÙŠØ±Ø© Ø§Ù„Ø°Ø§ØªÙŠØ© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©: {cv}")
    
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø³ÙˆØ¯Ø§Ø¡ (Ø§Ù„Ø¬Ù‡Ø§Øª Ø§Ù„ØªÙŠ ØªÙ… Ù…Ø±Ø§Ø³Ù„ØªÙ‡Ø§ Ø³Ø§Ø¨Ù‚Ø§Ù‹)
    applied = []
    if os.path.exists(DB_FILE):
        with open(DB_FILE, 'r') as f: applied = f.read().splitlines()

    emails = get_real_emails()
    count = 0
    
    for target in emails:
        if target not in applied:
            print(f"ğŸ“§ Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¥Ø±Ø³Ø§Ù„ Ø¥Ù„Ù‰: {target}...")
            if send_application_email(target):
                print(f"âœ… Ù†Ø¬Ø­ Ø§Ù„Ø¥Ø±Ø³Ø§Ù„!")
                with open(DB_FILE, 'a') as f: f.write(target + "\n")
                count += 1
                await asyncio.sleep(10) # ÙØªØ±Ø§Øª Ø±Ø§Ø­Ø© Ù„ØªØ¬Ù†Ø¨ Ø§Ù„Ø­Ø¸Ø±
            if count >= 10: break # Ø¥Ø±Ø³Ø§Ù„ 10 Ø¥ÙŠÙ…ÙŠÙ„Ø§Øª ÙÙŠ Ø§Ù„Ù…Ø±Ø© Ø§Ù„ÙˆØ§Ø­Ø¯Ø©

    # Ø¬Ù„Ø¨ Ø±ÙˆØ§Ø¨Ø· Ø§Ù„ØªÙ‚Ø¯ÙŠÙ… Ø§Ù„ÙŠØ¯ÙˆÙŠ
    direct_links = scrape_direct_links()
    if direct_links:
        print("\nğŸ”¥ ÙˆØ¸Ø§Ø¦Ù Ø¬Ø¯ÙŠØ¯Ø© (Ù‚Ø¯Ù… Ø¹Ù„ÙŠÙ‡Ø§ ÙŠØ¯ÙˆÙŠØ§Ù‹ Ø¨Ø§Ù„Ø±ÙˆØ§Ø¨Ø·):")
        for link in direct_links: print(f"ğŸ‘‰ {link}")

if __name__ == "__main__":
    asyncio.run(run_bot())
